{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/arda/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from datasets import GTA5, CityScapes\n",
    "from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "from train import train\n",
    "from utils import (save_results, plot_loss, plot_mIoU, plot_IoU)\n",
    "from train import train_dacs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('WANDB_API_KEY')\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Mapping from class IDs to labels\n",
    "id_to_label = {\n",
    "    0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence',\n",
    "    5: 'pole', 6: 'light', 7: 'sign', 8: 'vegetation', 9: 'terrain',\n",
    "    10: 'sky', 11: 'person', 12: 'rider', 13: 'car', 14: 'truck',\n",
    "    15: 'bus', 16: 'train', 17: 'motorcycle', 18: 'bicycle', 255: 'unlabeled'\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "NC=19\n",
    "NUM_WORKERS = 8\n",
    "cityscape_size = (128,256)\n",
    "GTA5_size = (1024,2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(cityscape_size[0], cityscape_size[1]),\n",
    "])\n",
    "transforms_GTA5 = A.Compose([\n",
    "    A.Resize(GTA5_size[0], GTA5_size[1]),\n",
    "])\n",
    "\n",
    "cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform=transforms)\n",
    "cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform=transforms)\n",
    "GTA5_dataset = GTA5('./GTA5', transform=transforms_GTA5)\n",
    "\n",
    "cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 DeepLabV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 2.5e-4\n",
    "model_deeplab = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='./models/deeplab_resnet_pretrained_imagenet.pth').cuda()\n",
    "optimizer_deeplab = torch.optim.Adam(model_deeplab.parameters(), lr=init_lr)\n",
    "\n",
    "deeplab_result = train( model_deeplab,\n",
    "                        loss_fn, optimizer_deeplab,\n",
    "                        cityscapes_train_dataloader,\n",
    "                        cityscapes_test_dataloader, \n",
    "                        5,\n",
    "                        'step2_DeepLabV2')\n",
    "save_results(model_deeplab, deeplab_result, \"deeplab_performance_metrics_2_1\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(deeplab_result, \"DeepLabV2\", \"step2_1\", \"CityScapes\", \"CityScapes\")\n",
    "plot_mIoU(deeplab_result, \"DeepLabV2\", \"step2_1\", \"CityScapes\", \"CityScapes\")\n",
    "plot_IoU(deeplab_result, \"DeepLabV2\", \"step2_1\", \"CityScapes\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_deeplab.state_dict(), \"./checkpoints/deeplab_model_2_1.pth\")\n",
    "# model_deeplab.load_state_dict(torch.load(\"./checkpoints/deeplab_model.pth\"))\n",
    "# model_deeplab.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 BiseNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_bisenet = BiSeNet(19, 'resnet18').cuda()\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "optimizer_bisenet = torch.optim.Adam(model_bisenet.parameters(), lr=init_lr)\n",
    "bisenet_result_2_2 = train(model_bisenet, loss_fn, optimizer_bisenet,cityscapes_train_dataloader,cityscapes_test_dataloader, 5,'step2_BiseNet')\n",
    "save_results(model_bisenet, bisenet_result_2_2, \"bisenet_performance_metrics_2_2\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "\n",
    "plot_loss(bisenet_result_2_2, \"BiSeNet\", \"step2_2\", \"CityScapes\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result_2_2, \"BiSeNet\", \"step2_2\", \"CityScapes\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result_2_2, \"BiSeNet\", \"step2_2\", \"CityScapes\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet.state_dict(), \"./checkpoints/bisenet_model_2_2.pth\")\n",
    "# model_bisenet.load_state_dict(torch.load(\"./checkpoints/bisenet_model.pth\"))\n",
    "# model_bisenet.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bisenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_bisenet_3_1 = BiSeNet(19, 'resnet18').cuda()\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "optimizer_bisenet_3_1 = torch.optim.Adam(model_bisenet_3_1.parameters(), lr=init_lr)\n",
    "bisenet_result_3_1 = train(model_bisenet_3_1, loss_fn, optimizer_bisenet_3_1,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n",
    "save_results(model_bisenet_3_1, bisenet_result_3_1, \"bisenet_performance_metrics_3_1\", height=GTA5_size[0], width=GTA5_size[1], iterations=10)\n",
    "plot_loss(bisenet_result_3_1, \"BiSeNet\", \"step3_1\", \"GTA5\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result_3_1, \"BiSeNet\", \"step3_1\", \"GTA5\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result_3_1, \"BiSeNet\", \"step3_1\", \"GTA5\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet_3_1.state_dict(), \"./checkpoints/bisenet_model_3_1.pth\")\n",
    "# model_bisenet_3_1.load_state_dict(torch.load(\"./checkpoints/bisenet_model_3_1.pth\"))\n",
    "# model_bisenet_3_1.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bisenet with augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentations = {\n",
    "    'transform1': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "    ]),\n",
    "    'transform2': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "    ]),\n",
    "    'transform3': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "    ]),\n",
    "    'transform4': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "    ]),\n",
    "    'transform5': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "    ]),\n",
    "    'transform6': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "    ])\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best = ''\n",
    "for key, value in augmentations.items():\n",
    "    cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform = value)\n",
    "    cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform = value)\n",
    "    GTA5_dataset = GTA5('./GTA5', transform = value, augmentations=value)\n",
    "\n",
    "\n",
    "    cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    model_bisenet_3_2 = BiSeNet(19, 'resnet18').cuda()\n",
    "    init_lr = 2.5e-4 #0.0001\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "    optimizer = torch.optim.Adam(model_bisenet_3_2.parameters(), lr=init_lr)\n",
    "\n",
    "    bisenet_result3_2 = train(model_bisenet_3_2, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n",
    "    \n",
    "        \n",
    "    save_results(model_bisenet_3_2, bisenet_result3_2, f\"bisenet_performance_metrics_3_1_{key}\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "    plot_loss(bisenet_result3_2, \"BiSeNet\", f\"step3_1_{key}\", \"GTA5\", \"CityScapes\")\n",
    "    plot_mIoU(bisenet_result3_2, \"BiSeNet\", f\"step3_1_{key}\", \"GTA5\", \"CityScapes\")\n",
    "    plot_IoU(bisenet_result3_2, \"BiSeNet\", f\"step3_1_{key}\", \"GTA5\", \"CityScapes\")\n",
    "    torch.save(model_bisenet_3_2.state_dict(), f\"./checkpoints/bisenet_model_3_1_{key}.pth\")\n",
    "    if best_score < bisenet_result3_2[3][-1]:\n",
    "        best_score = bisenet_result3_2[3][-1]\n",
    "        best = key\n",
    "best        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTA5_dataset = GTA5('./GTA5', transform=augmentations[best], FDA = 0.09)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "model_bisenet_4_1_FDA = BiSeNet(19, 'resnet18').cuda()\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model_bisenet_4_1_FDA.parameters(), lr=init_lr)\n",
    "\n",
    "bisenet_result4_1_FDA = train(model_bisenet_4_1_FDA, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n",
    "\n",
    "    \n",
    "save_results(model_bisenet_4_1_FDA, bisenet_result4_1_FDA, \"bisenet_performance_metrics_4_1_FDA\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(bisenet_result4_1_FDA, \"BiSeNet\", \"step4_1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result4_1_FDA, \"BiSeNet\", \"step4_1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result4_1_FDA, \"BiSeNet\", \"step4_1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "torch.save(model_bisenet_4_1_FDA.state_dict(), f\"./checkpoints/bisenet_model_4_1_FDA.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 DACS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- In the paper they say that they are using pretrained model. but in pseudocode they say that they are initializing the model with random parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTA5_dataset = GTA5('./GTA5', transform=augmentations[best], FDA = 0.09)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "model_bisenet_4_2_DACS = BiSeNet(19, 'resnet18').cuda()\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model_bisenet_4_2_DACS.parameters(), lr=init_lr)\n",
    "\n",
    "bisenet_result4_2_DACS = train_dacs(model_bisenet_4_2_DACS, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step4_2_DACS')\n",
    "save_results(model_bisenet_4_2_DACS, bisenet_result4_2_DACS, \"bisenet_performance_metrics_4_2_DACS\", height=GTA5_size[0], width=GTA5_size[1], iterations=10)\n",
    "plot_loss(bisenet_result4_2_DACS, \"BiSeNet\", \"step4_2_DACS\", \"GTA5 + CityScapes (DACS)\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result4_2_DACS, \"BiSeNet\", \"step4_2_DACS\", \"GTA5 + CityScapes (DACS)\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result4_2_DACS, \"BiSeNet\", \"step4_2_DACS\", \"GTA5 + CityScapes (DACS)\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet_4_2_DACS.state_dict(), \"./checkpoints/bisenet_model_4_2_DACS.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEMSEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
