{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mardaerendogru\u001b[0m (\u001b[33maeddea\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/arda/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from datasets import GTA5, CityScapes\n",
    "from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "from train import train\n",
    "from utils import (save_results, plot_loss, plot_mIoU, plot_IoU)\n",
    "from train import train_dacs\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('WANDB_API_KEY')\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Mapping from class IDs to labels\n",
    "id_to_label = {\n",
    "    0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence',\n",
    "    5: 'pole', 6: 'light', 7: 'sign', 8: 'vegetation', 9: 'terrain',\n",
    "    10: 'sky', 11: 'person', 12: 'rider', 13: 'car', 14: 'truck',\n",
    "    15: 'bus', 16: 'train', 17: 'motorcycle', 18: 'bicycle', 255: 'unlabeled'\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "NC=19\n",
    "NUM_WORKERS = 8\n",
    "cityscape_size = (256,512)\n",
    "GTA5_size = (256,512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 84, 417)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(cityscape_size[0], cityscape_size[1]),\n",
    "])\n",
    "transforms_GTA5 = A.Compose([\n",
    "    A.Resize(GTA5_size[0], GTA5_size[1]),\n",
    "])\n",
    "\n",
    "cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform=transforms)\n",
    "cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform=transforms)\n",
    "GTA5_dataset = GTA5('./GTA5', transform=transforms_GTA5)\n",
    "\n",
    "cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "len(cityscapes_train_dataloader), len(cityscapes_test_dataloader), len(GTA5_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 DeepLabV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_deeplab \u001b[38;5;241m=\u001b[39m get_deeplab_v2(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m, pretrain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pretrain_model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/deeplab_resnet_pretrained_imagenet.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      4\u001b[0m optimizer_deeplab \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_deeplab\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39minit_lr)\n\u001b[0;32m----> 6\u001b[0m deeplab_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_deeplab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_deeplab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcityscapes_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcityscapes_test_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep2_1_DeepLabV2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m save_results(model_deeplab, deeplab_result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeeplab_performance_metrics_2_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, height\u001b[38;5;241m=\u001b[39mcityscape_size[\u001b[38;5;241m0\u001b[39m], width\u001b[38;5;241m=\u001b[39mcityscape_size[\u001b[38;5;241m1\u001b[39m], iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     13\u001b[0m plot_loss(deeplab_result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepLabV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep2_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCityScapes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCityScapes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MLDL/semseg/MLDL2024_project1/train.py:64\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, train_dataloader, test_dataloader, epoch, project_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, label)\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 64\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     66\u001b[0m train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/SEMSEG/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SEMSEG/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SEMSEG/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 2.5e-4\n",
    "model_deeplab = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='./models/deeplab_resnet_pretrained_imagenet.pth').cuda()\n",
    "optimizer_deeplab = torch.optim.Adam(model_deeplab.parameters(), lr=init_lr)\n",
    "\n",
    "deeplab_result = train( model_deeplab,\n",
    "                        loss_fn, optimizer_deeplab,\n",
    "                        cityscapes_train_dataloader,\n",
    "                        cityscapes_test_dataloader, \n",
    "                        5,\n",
    "                        'step2_1_DeepLabV2')\n",
    "save_results(model_deeplab, deeplab_result, \"deeplab_performance_metrics_2_1\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(deeplab_result, \"DeepLabV2\", \"step2_1\", \"CityScapes\", \"CityScapes\")\n",
    "plot_mIoU(deeplab_result, \"DeepLabV2\", \"step2_1\", \"CityScapes\", \"CityScapes\")\n",
    "plot_IoU(deeplab_result, \"DeepLabV2\", \"step2_1\", \"CityScapes\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_deeplab.state_dict(), \"./checkpoints/deeplab_model_2_1.pth\")\n",
    "# model_deeplab.load_state_dict(torch.load(\"./checkpoints/deeplab_model.pth\"))\n",
    "# model_deeplab.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 BiseNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bisenet = BiSeNet(19, 'resnet18').cuda()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "optimizer_bisenet = torch.optim.Adam(model_bisenet.parameters(), lr=init_lr)\n",
    "bisenet_result_2_2 = train(model_bisenet, loss_fn, optimizer_bisenet,cityscapes_train_dataloader,cityscapes_test_dataloader, 5,'step2_BiseNet')\n",
    "save_results(model_bisenet, bisenet_result_2_2, \"bisenet_performance_metrics_2_2\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "\n",
    "plot_loss(bisenet_result_2_2, \"BiSeNet\", \"step2_2\", \"CityScapes\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result_2_2, \"BiSeNet\", \"step2_2\", \"CityScapes\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result_2_2, \"BiSeNet\", \"step2_2\", \"CityScapes\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet.state_dict(), \"./checkpoints/bisenet_model_2_2.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bisenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_bisenet_3_1 = BiSeNet(19, 'resnet18').cuda()\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "optimizer_bisenet_3_1 = torch.optim.Adam(model_bisenet_3_1.parameters(), lr=init_lr)\n",
    "bisenet_result_3_1 = train(model_bisenet_3_1, loss_fn, optimizer_bisenet_3_1,GTA5_dataloader,cityscapes_test_dataloader, 5,'step3_1_BiseNet')\n",
    "save_results(model_bisenet_3_1, bisenet_result_3_1, \"bisenet_performance_metrics_3_1\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(bisenet_result_3_1, \"BiSeNet\", \"step3_1\", \"GTA5\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result_3_1, \"BiSeNet\", \"step3_1\", \"GTA5\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result_3_1, \"BiSeNet\", \"step3_1\", \"GTA5\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet_3_1.state_dict(), \"./checkpoints/bisenet_model_3_1.pth\")\n",
    "# model_bisenet_3_1.load_state_dict(torch.load(\"./checkpoints/bisenet_model_3_1.pth\"))\n",
    "# model_bisenet_3_1.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bisenet with augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentations = {\n",
    "    'transform1': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "    ]),\n",
    "    'transform2': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "    ]),\n",
    "    'transform3': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "    ]),\n",
    "    'transform4': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "    ]),\n",
    "    'transform5': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "    ]),\n",
    "    'transform6': A.Compose([\n",
    "        A.Resize(GTA5_size[0],GTA5_size[1]),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "    ])\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best = ''\n",
    "for key, value in augmentations.items():\n",
    "    cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform = value)\n",
    "    cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform = value)\n",
    "    GTA5_dataset = GTA5('./GTA5', transform = value)\n",
    "\n",
    "\n",
    "    cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    model_bisenet_3_2 = BiSeNet(19, 'resnet18').cuda()\n",
    "    init_lr = 2.5e-4 #0.0001\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "    optimizer = torch.optim.Adam(model_bisenet_3_2.parameters(), lr=init_lr)\n",
    "\n",
    "    bisenet_result3_2 = train(model_bisenet_3_2, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 5,'step3_BiseNet')\n",
    "    \n",
    "        \n",
    "    save_results(model_bisenet_3_2, bisenet_result3_2, f\"bisenet_performance_metrics_3_2_{key}\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "    plot_loss(bisenet_result3_2, \"BiSeNet\", f\"step3_2_{key}\", \"GTA5\", \"CityScapes\")\n",
    "    plot_mIoU(bisenet_result3_2, \"BiSeNet\", f\"step3_2_{key}\", \"GTA5\", \"CityScapes\")\n",
    "    plot_IoU(bisenet_result3_2, \"BiSeNet\", f\"step3_2_{key}\", \"GTA5\", \"CityScapes\")\n",
    "    torch.save(model_bisenet_3_2.state_dict(), f\"./checkpoints/bisenet_model_3_2_{key}.pth\")\n",
    "    if best_score < bisenet_result3_2[3][-1]:\n",
    "        best_score = bisenet_result3_2[3][-1]\n",
    "        best = key\n",
    "best        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTA5_dataset = GTA5('./GTA5', transform=augmentations[best], FDA = 0.09)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "model_bisenet_4_1_FDA = BiSeNet(19, 'resnet18').cuda()\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model_bisenet_4_1_FDA.parameters(), lr=init_lr)\n",
    "\n",
    "bisenet_result4_1_FDA = train(model_bisenet_4_1_FDA, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 5,'step3_BiseNet')\n",
    "\n",
    "    \n",
    "save_results(model_bisenet_4_1_FDA, bisenet_result4_1_FDA, \"bisenet_performance_metrics_4_1_FDA\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(bisenet_result4_1_FDA, \"BiSeNet\", \"step4_1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result4_1_FDA, \"BiSeNet\", \"step4_1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result4_1_FDA, \"BiSeNet\", \"step4_1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "torch.save(model_bisenet_4_1_FDA.state_dict(), f\"./checkpoints/bisenet_model_4_1_FDA.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 DACS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- In the paper they say that they are using pretrained model. but in pseudocode they say that they are initializing the model with random parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arda/Documents/MLDL/semseg/MLDL2024_project1/wandb/run-20240522_135848-2b5mn291</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aeddea/step4_2_DACS/runs/2b5mn291' target=\"_blank\">silver-dream-20</a></strong> to <a href='https://wandb.ai/aeddea/step4_2_DACS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aeddea/step4_2_DACS' target=\"_blank\">https://wandb.ai/aeddea/step4_2_DACS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aeddea/step4_2_DACS/runs/2b5mn291' target=\"_blank\">https://wandb.ai/aeddea/step4_2_DACS/runs/2b5mn291</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115948ba97564752a8d71380729929ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0.0\n",
      "Step: 0.023980815347721823\n",
      "Step: 0.047961630695443645\n",
      "Step: 0.07194244604316546\n",
      "Step: 0.09592326139088729\n",
      "Step: 0.11990407673860912\n",
      "Step: 0.14388489208633093\n",
      "Step: 0.16786570743405277\n",
      "Step: 0.19184652278177458\n",
      "Step: 0.2158273381294964\n",
      "Step: 0.23980815347721823\n",
      "Step: 0.2637889688249401\n",
      "Step: 0.28776978417266186\n",
      "Step: 0.3117505995203837\n",
      "Step: 0.33573141486810554\n",
      "Step: 0.3597122302158273\n",
      "Step: 0.38369304556354916\n",
      "Step: 0.407673860911271\n",
      "Step: 0.4316546762589928\n",
      "Step: 0.4556354916067146\n",
      "Step: 0.47961630695443647\n",
      "Step: 0.5035971223021583\n",
      "Step: 0.5275779376498801\n",
      "Step: 0.5515587529976019\n",
      "Step: 0.5755395683453237\n",
      "Step: 0.5995203836930456\n",
      "Step: 0.6235011990407674\n",
      "Step: 0.6474820143884892\n",
      "Step: 0.6714628297362111\n",
      "Step: 0.6954436450839329\n",
      "Step: 0.7194244604316546\n",
      "Step: 0.7434052757793765\n",
      "Step: 0.7673860911270983\n",
      "Step: 0.7913669064748201\n",
      "Step: 0.815347721822542\n",
      "Step: 0.8393285371702638\n",
      "Step: 0.8633093525179856\n",
      "Step: 0.8872901678657075\n",
      "Step: 0.9112709832134293\n",
      "Step: 0.935251798561151\n",
      "Step: 0.9592326139088729\n",
      "Step: 0.9832134292565947\n",
      "Epoch: 0\n",
      "Train Loss: 1.4937553321429007, Validation Loss: 1.0729196908928098\n",
      "Train mIoU: 0.14619171861678903, Validation mIoU: 0.16389962260585794\n",
      "Step: 0.0\n",
      "Step: 0.023980815347721823\n",
      "Step: 0.047961630695443645\n",
      "Step: 0.07194244604316546\n",
      "Step: 0.09592326139088729\n",
      "Step: 0.11990407673860912\n",
      "Step: 0.14388489208633093\n",
      "Step: 0.16786570743405277\n",
      "Step: 0.19184652278177458\n",
      "Step: 0.2158273381294964\n",
      "Step: 0.23980815347721823\n",
      "Step: 0.2637889688249401\n",
      "Step: 0.28776978417266186\n",
      "Step: 0.3117505995203837\n",
      "Step: 0.33573141486810554\n",
      "Step: 0.3597122302158273\n",
      "Step: 0.38369304556354916\n"
     ]
    }
   ],
   "source": [
    "# GTA5_dataset = GTA5('./GTA5', transform=augmentations[best], FDA = 0.09)\n",
    "GTA5_dataset = GTA5('./GTA5', transform=transforms_GTA5, FDA = 0.09)\n",
    "\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "model_bisenet_4_2_DACS = BiSeNet(19, 'resnet18').cuda()\n",
    "init_lr = 2.5e-4 #0.0001\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model_bisenet_4_2_DACS.parameters(), lr=init_lr)\n",
    "\n",
    "bisenet_result4_2_DACS = train_dacs(model_bisenet_4_2_DACS, loss_fn, optimizer,GTA5_dataloader, cityscapes_train_dataloader,cityscapes_test_dataloader, 5,'step4_2_DACS', 20)\n",
    "save_results(model_bisenet_4_2_DACS, bisenet_result4_2_DACS, \"bisenet_performance_metrics_4_2_DACS\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(bisenet_result4_2_DACS, \"BiSeNet\", \"step4_2_DACS\", \"GTA5 + CityScapes (DACS)\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result4_2_DACS, \"BiSeNet\", \"step4_2_DACS\", \"GTA5 + CityScapes (DACS)\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result4_2_DACS, \"BiSeNet\", \"step4_2_DACS\", \"GTA5 + CityScapes (DACS)\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet_4_2_DACS.state_dict(), \"./checkpoints/bisenet_model_4_2_DACS.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor with shape [6, 1, 64, 64]\n",
    "mask = torch.randn(6, 1, 64, 64)\n",
    "\n",
    "# Squeeze the tensor to remove the dimension of size 1\n",
    "squeezed_mask = mask.squeeze(1)  # Specify dimension to ensure only the intended dimension is removed\n",
    "\n",
    "print(squeezed_mask.shape)  # Should print torch.Size([6, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEMSEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
