{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mardaerendogru\u001b[0m (\u001b[33maeddea\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "from datasets import GTA5, CityScapes\n",
    "from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from train import train\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "NC=19\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "def to_tensor_no_normalize(pil_image):\n",
    "    # Apply the resize transformation to the image\n",
    "    # Convert the PIL image to a tensor\n",
    "    return torch.tensor(np.array(pil_image, dtype=np.uint8))\n",
    "\n",
    "transform_cityscapes_image = transforms.Compose([\n",
    "    transforms.Resize((256, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_label = transforms.Compose([\n",
    "    transforms.Resize((256, 512), interpolation=Image.NEAREST),\n",
    "    transforms.Lambda(lambda img: to_tensor_no_normalize(img))\n",
    "])\n",
    "transform_cityscapes_label = transforms.Compose([\n",
    "    transforms.Resize((256, 512), interpolation=Image.NEAREST),\n",
    "    transforms.Lambda(lambda img: to_tensor_no_normalize(img))\n",
    "])\n",
    "\n",
    "cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "GTA5_dataset = GTA5('./GTA5', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "\n",
    "\n",
    "cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 DeepLabV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.001 #0.0001\n",
    "model = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='./models/deeplab_resnet_pretrained_imagenet.pth').cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "\n",
    "deeplab_result = train( model,\n",
    "                        loss_fn, optimizer,\n",
    "                        cityscapes_train_dataloader,\n",
    "                        cityscapes_test_dataloader, \n",
    "                        50,\n",
    "                        'step2_DeepLabV2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 BiseNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "bisenet_model = BiSeNet(20, 'resnet101').cuda()\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.001 #0.0001\n",
    "optimizer = torch.optim.Adam(bisenet_model.parameters(), lr=init_lr)\n",
    "result2_2 = train(bisenet_model, loss_fn, optimizer,cityscapes_train_dataloader,cityscapes_test_dataloader, 50,'step2_BiseNet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bisenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "bisenet_model = BiSeNet(20, 'resnet101').cuda()\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.001 #0.0001\n",
    "optimizer = torch.optim.Adam(bisenet_model.parameters(), lr=init_lr)\n",
    "result3_1 = train(bisenet_model, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bisenet with augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arda/Documents/MLDL/semseg/MLDL2024_project1/wandb/run-20240513_051803-ynpzpia1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aeddea/step3_BiseNet/runs/ynpzpia1' target=\"_blank\">denim-field-23</a></strong> to <a href='https://wandb.ai/aeddea/step3_BiseNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aeddea/step3_BiseNet' target=\"_blank\">https://wandb.ai/aeddea/step3_BiseNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aeddea/step3_BiseNet/runs/ynpzpia1' target=\"_blank\">https://wandb.ai/aeddea/step3_BiseNet/runs/ynpzpia1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2aad57fb6e468ab266b3cabe362064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 0.9527229992605799, Validation Loss: 1.3393097122510274\n",
      "Train mIoU: 0.11397026098410527, Validation mIoU: 0.1179773625920738\n",
      "Epoch: 1\n",
      "Train Loss: 0.8151436878336991, Validation Loss: 1.345504036971501\n",
      "Train mIoU: 0.1493951902184583, Validation mIoU: 0.11246220916350894\n",
      "Epoch: 2\n",
      "Train Loss: 0.7690537557613364, Validation Loss: 1.3212483071145558\n",
      "Train mIoU: 0.1633676347937043, Validation mIoU: 0.10447827280133798\n",
      "Epoch: 3\n",
      "Train Loss: 0.7305930418362149, Validation Loss: 1.1998044713622047\n",
      "Train mIoU: 0.17433308347725895, Validation mIoU: 0.11885606892088423\n",
      "Epoch: 4\n",
      "Train Loss: 0.6981318351462019, Validation Loss: 1.144949456055959\n",
      "Train mIoU: 0.18468218746683168, Validation mIoU: 0.13604399105600132\n",
      "Epoch: 5\n",
      "Train Loss: 0.6669123577271148, Validation Loss: 1.166615374031521\n",
      "Train mIoU: 0.1934911631200699, Validation mIoU: 0.13466933298964942\n",
      "Epoch: 6\n",
      "Train Loss: 0.6447407729048237, Validation Loss: 1.1015621225039165\n",
      "Train mIoU: 0.20150999430993394, Validation mIoU: 0.14668956993743112\n",
      "Epoch: 7\n",
      "Train Loss: 0.6236947947840611, Validation Loss: 1.121411274586405\n",
      "Train mIoU: 0.20799492294970248, Validation mIoU: 0.14484764426937674\n",
      "Epoch: 8\n",
      "Train Loss: 0.6078393475043116, Validation Loss: 1.067593291401863\n",
      "Train mIoU: 0.2117688146053067, Validation mIoU: 0.15597599452942093\n",
      "Epoch: 9\n",
      "Train Loss: 0.5919498441030653, Validation Loss: 1.2413584306126548\n",
      "Train mIoU: 0.21837237580364424, Validation mIoU: 0.13594763729420392\n",
      "Epoch: 10\n",
      "Train Loss: 0.5773010802783555, Validation Loss: 1.1964493166832697\n",
      "Train mIoU: 0.2237132128475799, Validation mIoU: 0.1451086240857699\n",
      "Epoch: 11\n",
      "Train Loss: 0.5618013554482723, Validation Loss: 1.0881839238461994\n",
      "Train mIoU: 0.22926474452844525, Validation mIoU: 0.1597600001011464\n",
      "Epoch: 12\n",
      "Train Loss: 0.5508540102617918, Validation Loss: 1.061810525400298\n",
      "Train mIoU: 0.23384184182600817, Validation mIoU: 0.15962514427941277\n",
      "Epoch: 13\n",
      "Train Loss: 0.5351716575862693, Validation Loss: 1.1854726416724068\n",
      "Train mIoU: 0.2393781932738304, Validation mIoU: 0.1507307047261451\n",
      "Epoch: 14\n",
      "Train Loss: 0.5240855554310824, Validation Loss: 1.1694454203049343\n",
      "Train mIoU: 0.24408146565141056, Validation mIoU: 0.1512690063505069\n",
      "Epoch: 15\n",
      "Train Loss: 0.5138464554322424, Validation Loss: 1.1167840432553064\n",
      "Train mIoU: 0.2483491826908494, Validation mIoU: 0.162827247638569\n",
      "Epoch: 16\n",
      "Train Loss: 0.499766658321559, Validation Loss: 1.186436347308613\n",
      "Train mIoU: 0.2542052990828515, Validation mIoU: 0.1558868323658081\n",
      "Epoch: 17\n",
      "Train Loss: 0.48451482563567677, Validation Loss: 1.1630672067403793\n",
      "Train mIoU: 0.26046099661492866, Validation mIoU: 0.15315313461526792\n",
      "Epoch: 18\n",
      "Train Loss: 0.4805786333066954, Validation Loss: 1.1542302817106247\n",
      "Train mIoU: 0.26249203233559987, Validation mIoU: 0.1570564512245482\n",
      "Epoch: 19\n",
      "Train Loss: 0.4654693941561152, Validation Loss: 1.0651597827672958\n",
      "Train mIoU: 0.269353299521145, Validation mIoU: 0.17347075145878318\n",
      "Epoch: 20\n",
      "Train Loss: 0.4529385540982802, Validation Loss: 1.104637739204225\n",
      "Train mIoU: 0.2758725992637848, Validation mIoU: 0.1640917644042647\n",
      "Epoch: 21\n",
      "Train Loss: 0.44686482078451617, Validation Loss: 1.1326693218378794\n",
      "Train mIoU: 0.27861295433621736, Validation mIoU: 0.1682068558527517\n",
      "Epoch: 22\n",
      "Train Loss: 0.43457190724585554, Validation Loss: 1.1075602237667357\n",
      "Train mIoU: 0.2837382874144797, Validation mIoU: 0.17246247657240524\n",
      "Epoch: 23\n",
      "Train Loss: 0.4315234573482038, Validation Loss: 1.1323998059545244\n",
      "Train mIoU: 0.286142289708445, Validation mIoU: 0.17008269125703482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m GTA5_dataset \u001b[38;5;241m=\u001b[39m GTA5(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./GTA5\u001b[39m\u001b[38;5;124m'\u001b[39m,augmentations\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     22\u001b[0m GTA5_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(GTA5_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mNUM_WORKERS)\n\u001b[0;32m---> 24\u001b[0m result3_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbisenet_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mGTA5_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcityscapes_test_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep3_BiseNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MLDL/semseg/MLDL2024_project1/train.py:51\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, cityscapes_train_dataloader, cityscapes_test_dataloader, epoch, project_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 51\u001b[0m train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m out_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(torch\u001b[38;5;241m.\u001b[39msoftmax(out,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m hist \u001b[38;5;241m=\u001b[39m fast_hist(out_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),label\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from tqdm.notebook import tqdm\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "bisenet_model = BiSeNet(20, 'resnet101').cuda()\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.025 #0.0001\n",
    "optimizer = torch.optim.Adam(bisenet_model.parameters(), lr=init_lr)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 512),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "    A.RandomFog(p=0.5),\n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])\n",
    "GTA5_dataset = GTA5('./GTA5',augmentations=transform)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "result3_1 = train(bisenet_model, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.Resize(256, 512),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.Rotate(limit=5, p=0.5,border_mode=1),\n",
    "#     A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# img_path = './Cityscapes/Cityspaces/images/train/hanover/hanover_000000_000164_leftImg8bit.png'\n",
    "# label_path = './Cityscapes/Cityspaces/gtFine/train/hanover/hanover_000000_000164_gtFine_labelTrainIds.png'\n",
    "# img = np.array(Image.open(img_path))\n",
    "# label = np.array(Image.open(label_path))\n",
    "# transformed = transform(image=img, mask=label)\n",
    "# img = transformed['image']\n",
    "# label = transformed['mask']\n",
    "# Image.fromarray(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEMSEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
