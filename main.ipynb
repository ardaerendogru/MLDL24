{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets import GTA5, CityScapes\n",
    "from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
    "from train import train\n",
    "from utils import (\n",
    "    poly_lr_scheduler, fast_hist, per_class_iou, compute_flops, \n",
    "    get_latency_and_fps, save_results, plot_loss, plot_mIoU, plot_IoU\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv('WANDB_API_KEY')\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Mapping from class IDs to labels\n",
    "id_to_label = {\n",
    "    0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence',\n",
    "    5: 'pole', 6: 'light', 7: 'sign', 8: 'vegetation', 9: 'terrain',\n",
    "    10: 'sky', 11: 'person', 12: 'rider', 13: 'car', 14: 'truck',\n",
    "    15: 'bus', 16: 'train', 17: 'motorcycle', 18: 'bicycle', 255: 'unlabeled'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "NC=19\n",
    "NUM_WORKERS = 8\n",
    "cityscape_size = (256,512)\n",
    "GTA5_size = (256,512)\n",
    "transform_cityscapes_image = transforms.Compose([\n",
    "    transforms.Resize(cityscape_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_gta5_image = transforms.Compose([\n",
    "    transforms.Resize(GTA5_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_gta5_label = transforms.Compose([\n",
    "    transforms.Resize(GTA5_size, interpolation=Image.NEAREST),\n",
    "    transforms.Lambda(lambda img: torch.tensor(np.array(img, dtype=np.uint8)))\n",
    "])\n",
    "transform_cityscapes_label = transforms.Compose([\n",
    "    transforms.Resize(cityscape_size, interpolation=Image.NEAREST),\n",
    "    transforms.Lambda(lambda img: torch.tensor(np.array(img, dtype=np.uint8)))\n",
    "])\n",
    "\n",
    "cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "GTA5_dataset = GTA5('./GTA5', transform_image=transform_gta5_image , transform_label=transform_gta5_label)\n",
    "\n",
    "\n",
    "cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 DeepLabV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.001 #0.0001\n",
    "model_deeplab = get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='./models/deeplab_resnet_pretrained_imagenet.pth').cuda()\n",
    "optimizer_deeplab = torch.optim.Adam(model_deeplab.parameters(), lr=init_lr)\n",
    "\n",
    "deeplab_result = train( model_deeplab,\n",
    "                        loss_fn, optimizer_deeplab,\n",
    "                        cityscapes_train_dataloader,\n",
    "                        GTA5_dataloader, \n",
    "                        5,\n",
    "                        'step2_DeepLabV2')\n",
    "save_results(model_deeplab, deeplab_result, \"deeplab_performance_metrics_2_1\", height=256, width=512, iterations=10)\n",
    "plot_loss(deeplab_result, \"DeepLabV2\", \"step2.1\", \"CityScapes\", \"CityScapes\")\n",
    "plot_mIoU(deeplab_result, \"DeepLabV2\", \"step2.1\", \"CityScapes\", \"CityScapes\")\n",
    "plot_IoU(deeplab_result, \"DeepLabV2\", \"step2.1\", \"CityScapes\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_deeplab.state_dict(), \"./checkpoints/deeplab_model.pth\")\n",
    "# model_deeplab.load_state_dict(torch.load(\"./checkpoints/deeplab_model.pth\"))\n",
    "# model_deeplab.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 BiseNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "model_bisenet = BiSeNet(20, 'resnet18').cuda()\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.001 #0.0001\n",
    "optimizer_bisenet = torch.optim.Adam(model_bisenet.parameters(), lr=init_lr)\n",
    "bisenet_result_2_2 = train(model_bisenet, loss_fn, optimizer_bisenet,cityscapes_train_dataloader,cityscapes_test_dataloader, 5,'step2_BiseNet')\n",
    "save_results(model_bisenet, bisenet_result_2_2, \"bisenet_performance_metrics_2_2\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "\n",
    "plot_loss(bisenet_result_2_2, \"BiSeNet\", \"step2.2\", \"CityScapes\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result_2_2, \"BiSeNet\", \"step2.2\", \"CityScapes\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result_2_2, \"BiSeNet\", \"step2.2\", \"CityScapes\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet.state_dict(), \"./checkpoints/bisenet_model.pth\")\n",
    "# model_bisenet.load_state_dict(torch.load(\"./checkpoints/bisenet_model.pth\"))\n",
    "# model_bisenet.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Bisenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "\n",
    "def to_tensor_no_normalize(pil_image):\n",
    "    # Apply the resize transformation to the image\n",
    "    # Convert the PIL image to a tensor\n",
    "    return torch.tensor(np.array(pil_image, dtype=np.uint8))\n",
    "\n",
    "transform_cityscapes_image = transforms.Compose([\n",
    "    transforms.Resize(cityscape_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_gta5_image = transforms.Compose([\n",
    "    transforms.Resize(GTA5_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_gta5_label = transforms.Compose([\n",
    "    transforms.Resize(GTA5_size, interpolation=Image.NEAREST),\n",
    "    transforms.Lambda(lambda img: to_tensor_no_normalize(img))\n",
    "])\n",
    "transform_cityscapes_label = transforms.Compose([\n",
    "    transforms.Resize(cityscape_size, interpolation=Image.NEAREST),\n",
    "    transforms.Lambda(lambda img: to_tensor_no_normalize(img))\n",
    "])\n",
    "\n",
    "cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "GTA5_dataset = GTA5('./GTA5', transform_image=transform_gta5_image , transform_label=transform_gta5_label)\n",
    "\n",
    "\n",
    "cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "model_bisenet_3_1 = BiSeNet(20, 'resnet18').cuda()\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "init_lr = 0.001 #0.0001\n",
    "optimizer_bisenet_3_1 = torch.optim.Adam(model_bisenet_3_1.parameters(), lr=init_lr)\n",
    "bisenet_result_3_1 = train(model_bisenet_3_1, loss_fn, optimizer_bisenet_3_1,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n",
    "save_results(model_bisenet_3_1, bisenet_result_3_1, \"bisenet_performance_metrics_3_1\", height=GTA5_size[0], width=GTA5_size[1], iterations=10)\n",
    "plot_loss(bisenet_result_3_1, \"BiSeNet\", \"step3.1\", \"GTA5\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result_3_1, \"BiSeNet\", \"step3.1\", \"GTA5\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result_3_1, \"BiSeNet\", \"step3.1\", \"GTA5\", \"CityScapes\")\n",
    "\n",
    "torch.save(model_bisenet_3_1.state_dict(), \"./checkpoints/bisenet_model_3_1.pth\")\n",
    "# model_bisenet_3_1.load_state_dict(torch.load(\"./checkpoints/bisenet_model_3_1.pth\"))\n",
    "# model_bisenet_3_1.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bisenet with augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from tqdm.notebook import tqdm\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "\n",
    "\n",
    "augmentations = {\n",
    "    'transform1': A.Compose([\n",
    "        A.Resize(GTA5_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'transform2': A.Compose([\n",
    "        A.Resize(GTA5_size),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'transform3': A.Compose([\n",
    "        A.Resize(GTA5_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'transform4': A.Compose([\n",
    "        A.Resize(GTA5_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'transform5': A.Compose([\n",
    "        A.Resize(GTA5_size),\n",
    "        A.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1), p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'transform6': A.Compose([\n",
    "        A.Resize(GTA5_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best = ''\n",
    "for key, value in augmentations.items():\n",
    "    cityscapes_train_dataset = CityScapes('./Cityscapes', 'train', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "    cityscapes_test_dataset = CityScapes('./Cityscapes', 'val', transform_image=transform_cityscapes_image , transform_label=transform_cityscapes_label)\n",
    "    GTA5_dataset = GTA5('./GTA5', transform_image=transform_gta5_image , transform_label=transform_gta5_label, augmentations=value)\n",
    "\n",
    "\n",
    "    cityscapes_train_dataloader = DataLoader(cityscapes_train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    model_bisenet_3_2 = BiSeNet(20, 'resnet18').cuda()\n",
    "    init_lr = 0.001 #0.0001\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "    optimizer = torch.optim.Adam(model_bisenet_3_2.parameters(), lr=init_lr)\n",
    "\n",
    "    bisenet_result3_2 = train(model_bisenet_3_2, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n",
    "    \n",
    "        \n",
    "    save_results(model_bisenet_3_2, bisenet_result3_2, \"bisenet_performance_metrics_3_1_{key}\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "    plot_loss(bisenet_result3_2, \"BiSeNet\", \"step3.1\", \"GTA5\", \"CityScapes\")\n",
    "    plot_mIoU(bisenet_result3_2, \"BiSeNet\", \"step3.1\", \"GTA5\", \"CityScapes\")\n",
    "    plot_IoU(bisenet_result3_2, \"BiSeNet\", \"step3.1\", \"GTA5\", \"CityScapes\")\n",
    "    torch.save(model_bisenet_3_2.state_dict(), f\"./checkpoints/bisenet_model_3_1_{key}.pth\")\n",
    "    if best_score < bisenet_result3_2[3][-1]:\n",
    "        best_score = bisenet_result3_2[3][-1]\n",
    "        best = key\n",
    "best        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTA5_dataset = GTA5('./GTA5', augmentations=augmentations[best], FDA = 0.09)\n",
    "GTA5_dataloader = DataLoader(GTA5_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "model_bisenet_4_1_FDA = BiSeNet(20, 'resnet18').cuda()\n",
    "init_lr = 0.001 #0.0001\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model_bisenet_4_1_FDA.parameters(), lr=init_lr)\n",
    "\n",
    "bisenet_result4_1_FDA = train(model_bisenet_4_1_FDA, loss_fn, optimizer,GTA5_dataloader,cityscapes_test_dataloader, 50,'step3_BiseNet')\n",
    "\n",
    "    \n",
    "save_results(model_bisenet_4_1_FDA, bisenet_result4_1_FDA, \"bisenet_performance_metrics_4_1_FDA\", height=cityscape_size[0], width=cityscape_size[1], iterations=10)\n",
    "plot_loss(bisenet_result4_1_FDA, \"BiSeNet\", \"step4.1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "plot_mIoU(bisenet_result4_1_FDA, \"BiSeNet\", \"step4.1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "plot_IoU(bisenet_result4_1_FDA, \"BiSeNet\", \"step4.1_FDA\", \"GTA5\", \"CityScapes\")\n",
    "torch.save(model_bisenet_4_1_FDA.state_dict(), f\"./checkpoints/bisenet_model_4_1_FDA.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEMSEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
